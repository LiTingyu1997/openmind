# Stable Diffusion XL
## Overview
Stable Diffusion XL (SDXL) was proposed in [SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis](https://huggingface.co/papers/2307.01952) by Dustin Podell, Zion English, Kyle Lacey, Andreas Blattmann, Tim Dockhorn, Jonas MÃ¼ller, Joe Penna, and Robin Rombach.

The abstract from the paper is:

*We present SDXL, a latent diffusion model for text-to-image synthesis. Compared to previous versions of Stable Diffusion, SDXL leverages a three times larger UNet backbone: The increase of model parameters is mainly due to more attention blocks and a larger cross-attention context as SDXL uses a second text encoder. We design multiple novel conditioning schemes and train SDXL on multiple aspect ratios. We also introduce a refinement model which is used to improve the visual fidelity of samples generated by SDXL using a post-hoc image-to-image technique. We demonstrate that SDXL shows drastically improved performance compared the previous versions of Stable Diffusion and achieves results competitive with those of black-box state-of-the-art image generators.*


## How to use

```pycon
    import mindspore as ms
    from mindone.diffusers import StableDiffusionXLInstructPix2PixPipeline
    from mindone.diffusers.utils import load_image

    resolution = 768
    image = load_image(
        "https://hf.co/datasets/diffusers/diffusers-images-docs/resolve/main/mountain.png"
    ).resize((resolution, resolution))
    edit_instruction = "Turn sky into a cloudy one"

    pipe = StableDiffusionXLInstructPix2PixPipeline.from_pretrained(
        "diffusers/sdxl-instructpix2pix-768", mindspore_dtype=ms.float16
    )

    edited_image = pipe(
        prompt=edit_instruction,
        image=image,
        height=resolution,
        width=resolution,
        guidance_scale=3.0,
        image_guidance_scale=1.5,
        num_inference_steps=30,
    )[0][0]
    edited_image
```